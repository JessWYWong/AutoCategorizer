//////////////////////////////////////////////////////////////////////////
//                            BasicTrainAndTest.cxx                     //
// =====================================================================//
//                                                                      //
//   Train the forest, save the trees, and test the results.            //
//                                                                      //
//////////////////////////////////////////////////////////////////////////

///////////////////////////////////////////////////////////////////////////
// _______________________Includes_______________________________________//
///////////////////////////////////////////////////////////////////////////

#include "CategoryReader.h"
#include "Tree.h"
#include "SignificanceMetrics.hxx"
#include "TRandom3.h"
#include <sstream>
#include <fstream>
#include <map>


//////////////////////////////////////////////////////////////////////////
// ______________________Categorization_Settings _______________________//
/////////////////////////////////////////////////////////////////////////

// Set the settings for the regression here. You may choose to overwrite these values in
// main if you want input from the terminal to determine the settings.

// Fundamental settings for the regression.
Int_t nodes = 4;
int nbins = 20;

// Choose which significance function to use.
SignificanceMetric* sm = new PoissonSignificance();
                  //sm = new AsimovSignificance();

// Whether to save the trees from the regression into a directory specified later.
bool saveTree = true;

// Where to save the trees.
TString treeDirectory("./");

//////////////////////////////////////////////////////////////////////////
// ______________________Load Info Into Data Structures________________//
/////////////////////////////////////////////////////////////////////////

void loadEvents(std::vector<Event*>& events, int numSignal, int numBackground)
{
// An example of how to load information into the Event data structure
// Here we use generated data with x1,x2 as features generating the histovar variable.
// Compare signal + background and background hypotheses along histovar variable.
// Let events near x1=1,x2=1 be signal and events near x1=-1,x2=-1 be background

    TRandom3 r(0);
    // Load signal events
    for(unsigned int i=0; i<numSignal; i++)
    {
        // Signal distribution along histovar generated by gaussians x1,x2 centered at 1,1
        // with no info about x1 and x2 this is a gaussian centered at 0
        // Events w/ x1,x2 near 1,1 are likely signal
        // Positive x1,x2 
        double x1 = r.Gaus(1,1);     // feature 1 
        double x2 = r.Gaus(1,1);     // feature 2 
        double histovar = r.Gaus(x1+x2-2,0.1);  // Background (null) and Signal + Background hypotheses compared 
                                                // via histograms of this variable. Set distribution for signal. 
        
        Event* e = new Event(); // The data structure the autocategorizer uses for training and evaluation
        e->id = i;              // uniquely identify the event if you want to                

        // discretize histovar into 20 bins of width 0.25 starting at -2.5 and ending at 2.5
        e->bin = (int) ((histovar-0)/0.25);                          
        if(histovar >= 2.5) e->bin = 19;
        if(histovar <= -2.5) e->bin = 0;
        //std::cout << e->id << ": " << " bin = " << e->bin <<  " histovar = " << histovar << std::endl;

        e->data = std::vector<double>(3); // data vector should be N_features + 1

        e->weight = 0.001;       // weight the signal by some amount (scale the signal distribution)
        e->trueValue = 1;      // signal is 1

        e->data[0] = 1;        // this was a specially reserved location when the code was for boosted decision trees (BDTs).
                               // the BDT code was repurposed for this autocategorizer code, and no longer uses data[0].  
                               // Fill data[0] with anything.
                               
        e->data[1] = x1;       // load first feature into data[1] 
        e->data[2] = x2;       // load second feature into data[2], etc 

        events.push_back(e);
    }

    // load background events
    for(unsigned int i=0; i<numBackground; i++)
    {
        // signal histo appears as gaussian at x1+x2-2, generated by x1,x2 = 1,1
        // with no info about x1 and x2 this is a gaussian centered at 0
        // if x1 or x2 are negative then the event is more likely to be background
        double x1 = r.Gaus(-1,1);   // feature 1           
        double x2 = r.Gaus(-1,1);   // feature 2           
        double histovar = r.Gaus(x1+x2+2,0.25);  // S and S+B hypothesis compared via histograms along this variable
                                                 // set distribution for background
        
        Event* e = new Event(); 
        e->id = numSignal + i;  

        e->bin = (int) ((histovar+2.5)/0.25);                          
        if(histovar >= 2.5) e->bin = 19;
        if(histovar <= -2.5) e->bin = 0;
        //std::cout << e->id << ": " << " bin = " << e->bin <<  " histovar = " << histovar << std::endl;

        e->data = std::vector<double>(3); // data vector should be N_features + 1

        e->weight = 1;         // weight the signal or bkg event by some amount
        e->trueValue = 0;      // background is 0
        e->data[0] = 0;        // dummy value 
                               
                               
        e->data[1] = x1;       // load first feature into data[1] 
        e->data[2] = x2;       // load second feature into data[2], etc 

        events.push_back(e);
    }
}

//////////////////////////////////////////////////////////////////////////
// ______________________Regression_________ ___________________________//
/////////////////////////////////////////////////////////////////////////

void buildCategorizationTree()
{
// Build a tree and save it in xml

  ///////////////////////////////////
  // Train 
  ///////////////////////////////////

  // The training and testing events.
  std::vector<Event*> trainingEvents = std::vector<Event*>();

  loadEvents(trainingEvents, 10000, 10000);

  std::cout << std::endl << "Number of training events: " << trainingEvents.size() << std::endl << std::endl;

  // Initialize new forest.
  Tree* tree = new Tree(trainingEvents, nbins);

  // Output the parameters of the current run. 
  std::cout << "=======================================" << std::endl;
  std::cout << "Nodes: " << nodes << std::endl;
  std::cout << "Significance Metric: " << sm->name << std::endl;
  std::cout << "=======================================" << std::endl;
  
  // Do the regression and save the trees.
  tree->buildTree(nodes, sm);

  // Output the save directory to the screen.
  TString savename = "tree.xml";
  if(saveTree)
  {
      std::cout << "save tree to: " << treeDirectory+savename << std::endl;
      tree->saveToXML(treeDirectory+savename);
  }


  // Rank the variable importance and output it to the screen.
  std::vector<std::string> rank;
  tree->outputVariableRanking(rank);

  delete tree;

  // ----------------------------------------------------
  ///////////////////////////////////////////////////////

  XMLCategorizer xmlc(treeDirectory+savename);
  xmlc.outputCategories();
}


//////////////////////////////////////////////////////////////////////////
// ______________________Main___________________________________________//
//////////////////////////////////////////////////////////////////////////

int main(int argc, char* argv[])
{
// Run a regression with the appropriate settings.

    // Gather regression settings from the command line if you want.
    // Then you can run as ./TrainAndEvaluate setting1 setting2 ...

    // Simply overwrite the settings at the beginning
    // with those from the command line like so.

    for(int i=1; i<argc; i++)
    {
        std::stringstream ss;
        ss << argv[i];
        //if(i==1) ss >> mode;
    }

    buildCategorizationTree();
    return 0;
}
